{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WIQZUWJLB4jL"
   },
   "source": [
    "# 概要\n",
    "MNISTの分類を、全結合型ニューラルネットワークで行う。\n",
    "* 第9回実習と同じモデル\n",
    "* 入力成分の順番をランダムに入れ替え"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GXrmOxLSGBT8"
   },
   "source": [
    "# 乱数シードの固定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "st7YNgiuGBT-"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JfRf4eR_GeBj"
   },
   "source": [
    "# 関数 save_fig：図の保存用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xld2BtdjGBUA"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def save_fig(plt, file_prefix):\n",
    "    if file_prefix == '':\n",
    "        return\n",
    "    \n",
    "    parent = os.path.dirname(os.path.abspath(file_prefix))\n",
    "    os.makedirs(parent, exist_ok=True)\n",
    "    plt.savefig(f'{file_prefix}.pdf', transparent=True, bbox_inches='tight', pad_inches = 0)\n",
    "    plt.savefig(f'{file_prefix}.png', transparent=True, dpi=300, bbox_inches='tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V5pR7YmtGBUB"
   },
   "source": [
    "# 関数 show_prediction：MNISTに対する予測結果の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H-iarsZoGBUD"
   },
   "outputs": [],
   "source": [
    "def show_prediction(x, y_true, y_pred, ids, file_prefix=''):\n",
    "    '''\n",
    "    手書き数字の認識結果を表示する。\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    model : Sequential\n",
    "        ニューラルネットワーク・モデル\n",
    "    '''\n",
    "\n",
    "    img = x[ids].reshape((len(ids), nx, ny))\n",
    "\n",
    "    labels = y_true[ids]\n",
    "    preds = y_pred[ids]\n",
    "\n",
    "    # AIが認識した結果を画像と一緒に提示する\n",
    "    plt.figure(2, figsize=(12, 8))\n",
    "    plt.gray()\n",
    "    for i in range(len(ids)):\n",
    "        plt.subplot(8, 12, i + 1)\n",
    "        plt.pcolor(img[i])\n",
    "        plt.text(22, 25.5, \"%d\" % preds[i], fontsize=12, color='yellow')\n",
    "        if preds[i] != labels[i]:\n",
    "            plt.plot([0, nx - 1], [1, 1], color='red', linewidth=5)\n",
    "        \n",
    "        plt.xlim(0, nx - 1)\n",
    "        plt.ylim(ny - 1, 0)\n",
    "        plt.xticks([], '')\n",
    "        plt.yticks([], '')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_fig(plt, file_prefix=file_prefix)\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4wXce_fTDI3Y"
   },
   "source": [
    "# 関数 show_mnist_images：MNISTの表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7AN1roMDDIGJ"
   },
   "outputs": [],
   "source": [
    "def show_mnist_images(x, y_true, ids, ny=28, nx=28, file_prefix=''):\n",
    "    '''\n",
    "    カラー画像のサンプルを表示する。\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    x: ndarray\n",
    "        カラー画像。形状(N)。N:データ数\n",
    "    y_true: ndarray\n",
    "        データxに対応するクラスラベルの正解インデックス。形状(N)\n",
    "    labels: list\n",
    "        クラスラベル\n",
    "    ids: ndarray\n",
    "        表示するデータのインデックス\n",
    "    ny: int\n",
    "        縦方向画素数\n",
    "    nx: int\n",
    "        横方向画素数\n",
    "    file_prefix: str\n",
    "        保存時のファイルプレフィックス\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    なし\n",
    "    '''\n",
    "\n",
    "    img = x[ids].reshape((len(ids), nx, ny))\n",
    "\n",
    "    trues = y_true[ids]\n",
    "\n",
    "    plt.figure(figsize=(24, 16))\n",
    "    for i in range(len(ids)):\n",
    "        plt.subplot(8, 12, i + 1)\n",
    "        plt.imshow(img[i], cmap='gray')\n",
    "        t = trues[i]\n",
    "        plt.title(f'{t}', fontsize=12)       \n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    save_fig(plt, file_prefix=file_prefix)\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B8fdkZLPGBUE"
   },
   "source": [
    "# 関数 evaluate：性能評価関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xI59MmnTGBUF"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "import seaborn as sns\n",
    "\n",
    "def evalulate(x, y_true, y_pred, file_prefix=''):\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average=None)\n",
    "    recall = recall_score(y_true, y_pred, average=None)\n",
    "    print('正解率')\n",
    "    print(f' {accuracy:.2f}')\n",
    "    \n",
    "    class_labels = []\n",
    "\n",
    "    num_classes = np.max(y_true) + 1\n",
    "    for i in range(num_classes):\n",
    "        class_labels.append(f'{i:4d}')\n",
    "    \n",
    "    precision_str = []\n",
    "    recall_str = []\n",
    "    for i in range(num_classes):\n",
    "        precision_str.append(f'{precision[i]:.2f}')\n",
    "        recall_str.append(f'{recall[i]:.2f}')\n",
    "\n",
    "    print('精度')\n",
    "    print(' ' + ' '.join(class_labels))\n",
    "    print(' ' + ' '.join(precision_str))\n",
    "                             \n",
    "    print('再現率')\n",
    "    print(' ' + ' '.join(class_labels))\n",
    "    print(' ' + ' '.join(recall_str))\n",
    "\n",
    "    plt.figure(figsize = (10,7))\n",
    "    sns.heatmap(cm, annot=True, fmt='3d', square=True, cmap='hot')\n",
    "    plt.tight_layout()\n",
    "    save_fig(plt, file_prefix=file_prefix)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hDj_hzAKGBUG"
   },
   "source": [
    "# 関数 show_history：学習過程の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "19OeGA2sGBUH"
   },
   "outputs": [],
   "source": [
    "def show_history(history, file_prefix=''):\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.subplots_adjust(wspace=0.2)\n",
    "    \n",
    "    # 学習曲線の表示\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], 'black', label='Training')\n",
    "    plt.plot(history.history['val_loss'], 'cornflowerblue', label='Test')\n",
    "    plt.legend(fontsize=16)\n",
    "    plt.xlabel('Epochs', fontsize=16)\n",
    "    plt.ylabel('Value', fontsize=16)\n",
    "    plt.title('Loss', fontsize=16)\n",
    "    plt.ylim(0, )\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)   \n",
    "    plt.grid(True)\n",
    "    \n",
    "    # 精度表示\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], 'black', label='Training')\n",
    "    plt.plot(history.history['val_accuracy'], 'cornflowerblue', label='Test')\n",
    "    plt.legend(fontsize=16)\n",
    "    plt.xlabel('Epochs', fontsize=16)\n",
    "    plt.ylabel('Value', fontsize=16)\n",
    "    plt.title('Accuracy', fontsize=16)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    plt.ylim(0, 1.2)\n",
    "    plt.grid(True)\n",
    "\n",
    "    save_fig(plt, file_prefix)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "20MdYUl9GBUI"
   },
   "source": [
    "# 関数 load_mnist：教師データを準備する関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ta8RoqyGGBUI"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def load_mnist():\n",
    "    \"\"\"\n",
    "    手書き数字データセットMNISTを全結合型ニューラルネットワークの教師データとして用意する。\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    x_train: ndarray\n",
    "        訓練データの画像配列。形状(60000, 784)\n",
    "    y_train: ndarray\n",
    "        訓練データのクラスラベル。one-hotベクトル化済み。形状(60000, 10)\n",
    "    x_test: ndarray\n",
    "        テストデータの画像配列。形状(10000, 784)\n",
    "    y_test: ndarray\n",
    "        テストデータのクラスラベル。one-hotベクトル化済み。形状(10000, 10)\n",
    "    ny: int\n",
    "        画像の縦方向画素数\n",
    "    nx: int\n",
    "        画像の横方向画素数\n",
    "    num_classes: int\n",
    "        クラス数\n",
    "    \"\"\"\n",
    "    # MNISTデータセットをTensorFlowのサイトからロード\n",
    "    # (訓練データ画像, 訓練データ・クラスラベル), (テストデータ画像, テストデータ・クラスラベル)\n",
    "    (x_train0, y_train0), (x_test0, y_test0) = mnist.load_data()\n",
    "\n",
    "    # 訓練データの準備\n",
    "    print('訓練データ')\n",
    "    print('画像枚数 =', len(x_train0))\n",
    "\n",
    "    # 先頭の画像を取り出して、形状を取得\n",
    "    ny, nx = x_train0[0].shape\n",
    "    print('画像の縦方向画素数 =', ny)\n",
    "    print('画像の横方向画素数 =', nx)\n",
    "\n",
    "    # 訓練データ数 60000\n",
    "    # 1つの画像は 28 x 28 = 784画素\n",
    "    # 0から59999の各行には1個の画像が格納される。\n",
    "    # 全結合層へ入力するため、各画像をny * nx個の成分を持つ1次元配列へ変換。\n",
    "    x_train = x_train0.reshape(len(x_train0), ny * nx)\n",
    "\n",
    "    x_train = x_train.astype('float32')   # 要素値の型をfloat32へ変更\n",
    "    # 画素値の最大値255を使い、画像の値を0以上1以下の範囲にする（正規化）\n",
    "    x_train = x_train / 255               \n",
    "\n",
    "    # クラス数。0から9の数字なので、10個\n",
    "    num_classes = np.max(y_train0) + 1\n",
    "    print('クラス数 =', num_classes)\n",
    "\n",
    "    # one-hotベクトル化\n",
    "    # なぜこう書けるのか、わからない人は実習資料を参照\n",
    "    mat = np.identity(num_classes)\n",
    "    y_train = mat[y_train0]\n",
    "    print('クラスラベルの形状 =', y_train.shape)\n",
    "\n",
    "    # テストデータの準備\n",
    "    # テストデータ数 10000\n",
    "    print('\\nテストデータ')\n",
    "    print('画像枚数 =', len(x_test0))\n",
    "\n",
    "    # テストデータ数 10000\n",
    "    # 1つの画像は 28 x 28 = 784画素\n",
    "    # 0から9999の各行には1個の画像が格納される。\n",
    "    # 全結合層へ入力するため、各画像をny * nx個の成分を持つ1次元配列へ変換。\n",
    "    x_test = x_test0.reshape(len(x_test0), ny * nx)\n",
    "    x_test = x_test.astype('float32')  # 要素値の型をfloat32へ変更\n",
    "    # 画素値の最大値255を使い、画像の値を0以上1以下の範囲にする（正規化）\n",
    "    x_test = x_test / 255\n",
    "    \n",
    "    y_test = mat[y_test0]              # one-hotベクトル化\n",
    "\n",
    "    return x_train, y_train, x_test, y_test, ny, nx, num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R0h2usorGBUV"
   },
   "source": [
    "# 実習9.1：10層の中間層（活性化関数ReLU）を持つmodel2を構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZJBYX0yjGBUV",
    "outputId": "c81bbc3d-af6c-4b97-f012-ed52eb5569a4"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# MNIST教師データを再生成\n",
    "# 戻り値の各変数の役割は関数定義を参照。\n",
    "x_train, y_train, x_test, y_test, ny, nx, num_classes = load_mnist()\n",
    "\n",
    "ids = range(96) # 可視化するデータの番号0から95\n",
    "print('成分の入れ替え前')\n",
    "show_mnist_images(x_train, np.argmax(y_train, axis=1), ids, file_prefix='before_shuffle')\n",
    "\n",
    "# 画像を1次元配列とみなして、成分を入れ替える\n",
    "random_idx = np.arange(nx * ny)\n",
    "random.shuffle(random_idx)\n",
    "x_train = x_train[:, random_idx]\n",
    "x_test = x_test[:, random_idx]\n",
    "\n",
    "print('成分の入れ替え後：学習に使用')\n",
    "show_mnist_images(x_train, np.argmax(y_train, axis=1), ids, file_prefix='after_shuffle')\n",
    "\n",
    "# ネットワークのパラメータ（重みとバイアス）を初期化する際の乱数シードを固定\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "n_hidden = 10 # 中間層数\n",
    "\n",
    "# ネットワークモデルを生成。層（レイヤー）の容器と考える。\n",
    "model1 = Sequential()\n",
    "\n",
    "# 最初の中間層を追加\n",
    "model1.add(Dense(input_dim=ny*nx,   # 入力層のニューロン数(入力データの成分数)\n",
    "                 units=10,          # 中間層1のニューロン数\n",
    "                 activation='relu', # 活性化関数ReLU\n",
    "                 name='hidden1'))   # 中間層1の名前\n",
    "\n",
    "# 2から9番目の中間層を追加\n",
    "for i in range(2, n_hidden + 1):\n",
    "    model1.add(Dense(units=10,           # 中間層iのニューロン数\n",
    "                     activation='relu',  # 活性化関数ReLU\n",
    "                     name=f'hidden{i}')) # 中間層iの名前\n",
    "\n",
    "# 出力層を追加\n",
    "model1.add(Dense(units=10,              # 出力層のニューロン数(クラス数)\n",
    "                 activation='softmax',  # 活性化関数\n",
    "                 name='output'))        # 出力層の名前\n",
    "\n",
    "model1.compile(optimizer='Adam',                # パラメータの最適化手法にAdamを指定\n",
    "               loss='categorical_crossentropy', # 損失関数\n",
    "               metrics=['accuracy'])            # 損失の他にモニターする指標として正解率を指定\n",
    "\n",
    "# モデルの要約情報を表示\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LCvBYVN_GBUW"
   },
   "source": [
    "# 実習9.2：model2の学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qQhxOjWlGBUW",
    "outputId": "a3e9504f-7010-46f6-eb7e-0ad833f50913",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 学習開始。終了後、学習の履歴がhistory2に代入される。\n",
    "history1 = model1.fit(x_train,  # 訓練データ：入力画像\n",
    "                      y_train,  # 訓練データ：クラスラベル\n",
    "                      epochs=500,  # エポック数\n",
    "                      batch_size=1000, # バッチサイズ\n",
    "                      shuffle=True,    # 学習時にデータの並びをシャッフル\n",
    "                      validation_data=(x_test, y_test)) # 学習過程での汎化能力の推定のためテストデータを指定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ofwc4U2wGBUX"
   },
   "source": [
    "# 実習9.3：model1の学習の履歴と汎化能力の推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "XJKmLJWeGBUX",
    "outputId": "0cdb0b15-d0f6-4d52-f2b5-25de2143eda0"
   },
   "outputs": [],
   "source": [
    "# 学習の履歴（損失と正解率の変化）を表示\n",
    "show_history(history1, file_prefix='9.3_loss_and_acc')\n",
    "\n",
    "# 学習したモデルを使い、テストデータのクラスラベルを予測\n",
    "y_pred = model1.predict(x_test)\n",
    "\n",
    "# 各データについて、最大の予測確率をもつクラスラベルを取得\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# 正解（one-hotベクトル）をクラスラベルに戻す\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# 混同行列、正解率、精度、再現率を評価\n",
    "evalulate(x_test, y_true, y_pred, file_prefix='9.3_cm')\n",
    "\n",
    "# 予測結果の一部を可視化する\n",
    "ids = range(96) # 可視化するデータの番号0から95\n",
    "\n",
    "# データの番号0から95について、予測結果を可視化\n",
    "show_prediction(x_test, y_true, y_pred, ids, file_prefix='9.3_digits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U4Bq9WFtxEda"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "全結合型ニューラルネットワーク_MNIST分類_第10回実習と同じモデル.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "232px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
